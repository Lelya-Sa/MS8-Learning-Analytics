# Phase 1A Debate #3: Database Migration Strategy

**Debate Information**
- **Phase**: 1A - Requirements Gathering
- **Topic**: Database Schema Migration & Management Strategy
- **Participants**: TL (Tech Lead), DD (Database Developer), DA (DevOps Architect), BE (Backend Engineer), SA (Software Architect)
- **Debate Format**: 15 rounds until consensus
- **Decision Impact**: Database reliability, deployment process, team workflow
- **Date**: October 24, 2025

---

## 📋 Context

**Question**: How should MS8 manage database schema migrations?

**Options**:
1. **Prisma Migrate** - Official Prisma migration tool
2. **Raw SQL Migrations** - Hand-written SQL migration files
3. **Supabase Migrations** - Platform-native migration tool
4. **node-pg-migrate** - PostgreSQL migration library
5. **Hybrid (Prisma + Raw SQL fallback)** - Prisma for simple changes, SQL for complex

**Technical Context**:
- PostgreSQL via Supabase
- Prisma ORM already in use
- Need: Row Level Security (RLS) policies
- Need: Materialized views for comparison analytics
- Need: Partitioned tables for long-term storage
- Team: More familiar with ORMs than raw SQL

---

## 🎯 Round 1-5: Quick Consensus (Prisma Migrate)

### **TL (Tech Lead)** [Round 1]
**Recommendation: Option 1 (Prisma Migrate)**

Rationale:
- ✅ Already using Prisma ORM
- ✅ Schema and migrations in one place (schema.prisma)
- ✅ Type-safe (generates TypeScript/JSDoc types)
- ✅ Git-friendly (migration files are tracked)
- ✅ Team familiarity (lower learning curve)

**Concern**: Prisma doesn't support RLS policies, materialized views, or partitioning natively.

**Solution**: Use Prisma for schema, raw SQL for advanced PostgreSQL features.

### **DD (Database Developer)** [Round 1]
**Agreement with caveat**:

Prisma Migrate is good for:
- ✅ Tables, columns, indexes
- ✅ Foreign keys, constraints
- ✅ Simple data types

Need raw SQL for:
- ❌ RLS policies (security requirement)
- ❌ Materialized views (comparison analytics)
- ❌ Table partitioning (7-year retention)
- ❌ pg-boss schema (managed by pg-boss itself)
- ❌ PostgreSQL-specific features (JSONB operators, full-text search)

**Proposal**: Prisma Migrate + separate SQL migration files for advanced features.

### **DA (DevOps Architect)** [Round 2]
**Support Prisma Migrate with this structure**:

```
database/
├── prisma/
│   ├── schema.prisma          # Main schema (Prisma manages)
│   └── migrations/            # Auto-generated by Prisma
│       ├── 20251024_init/
│       └── 20251025_add_users/
├── sql-migrations/            # Manual SQL (advanced features)
│   ├── 001_rls_policies.sql
│   ├── 002_materialized_views.sql
│   └── 003_partitioning.sql
└── migrate.js                 # Custom script: Prisma + SQL
```

**Deployment flow**:
1. Run `prisma migrate deploy` (schema changes)
2. Run SQL migrations (advanced features)
3. Verify with health check

### **BE (Backend Engineer)** [Round 3]
**Strongly support Prisma Migrate**:

Developer experience:
```bash
# Make schema change
vim prisma/schema.prisma

# Generate migration
npx prisma migrate dev --name add_analytics_table

# Apply to production
npx prisma migrate deploy
```

Simple, predictable, version-controlled.

For advanced SQL:
```bash
# Add SQL migration
vim sql-migrations/004_new_rls_policy.sql

# Apply manually (or in custom script)
psql $DATABASE_URL < sql-migrations/004_new_rls_policy.sql
```

Clear separation.

### **SA (Software Architect)** [Round 4]
**Architecture perspective: Hybrid is correct**:

**Why not pure Prisma**:
- Prisma doesn't support PostgreSQL-specific features we NEED

**Why not pure SQL**:
- Loses Prisma's type generation and schema sync
- Team would need to manually maintain Prisma schema + SQL files

**Why Hybrid**:
- ✅ Best of both worlds
- ✅ Prisma for 90% of changes (tables, columns)
- ✅ Raw SQL for 10% of changes (RLS, views, partitions)
- ✅ Clear separation of concerns

---

## 🎯 Round 5-10: Implementation Details

### **TL (Tech Lead)** [Round 5]
**Implementation plan**:

**Phase 1: Prisma Schema**
```prisma
// prisma/schema.prisma
generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model User {
  id             String   @id @default(uuid())
  email          String   @unique
  organizationId String   @map("organization_id")
  createdAt      DateTime @default(now()) @map("created_at")
  
  @@map("users")
}

model LearnerAnalytics {
  id        String   @id @default(uuid())
  userId    String   @map("user_id")
  roleId    String   @map("role_id")
  data      Json
  createdAt DateTime @default(now()) @map("created_at")
  
  @@map("learner_analytics")
  @@index([userId, roleId])
}
```

**Phase 2: SQL Migrations**
```sql
-- sql-migrations/001_rls_policies.sql
ALTER TABLE learner_analytics ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view own analytics"
ON learner_analytics FOR SELECT
USING (auth.uid() = user_id);
```

### **DD (Database Developer)** [Round 6]
**SQL Migrations needed**:

**1. RLS Policies** (Security requirement):
```sql
-- For each table with organizationId
ALTER TABLE learner_analytics ENABLE ROW LEVEL SECURITY;

CREATE POLICY "org_isolation"
ON learner_analytics FOR ALL
USING (organization_id = current_setting('app.current_org_id')::TEXT);
```

**2. Materialized Views** (Comparison analytics):
```sql
CREATE MATERIALIZED VIEW mv_comparison_aggregates AS
SELECT
  organization_id,
  user_role,
  AVG((data->>'skillsAcquired')::NUMERIC) as avg_skills,
  PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY (data->>'skillsAcquired')::NUMERIC) as p50_skills
FROM learner_analytics
GROUP BY organization_id, user_role;

CREATE INDEX idx_mv_comparison ON mv_comparison_aggregates(organization_id, user_role);
```

**3. Table Partitioning** (7-year retention):
```sql
-- Partition aggregated_analytics by year
CREATE TABLE aggregated_analytics_2025 PARTITION OF aggregated_analytics
FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');
```

### **DA (DevOps Architect)** [Round 7]
**Deployment automation**:

```javascript
// database/migrate.js
const { exec } = require('child_process');
const fs = require('fs');
const { Pool } = require('pg');

async function migrate() {
  // Step 1: Prisma migrations
  console.log('Running Prisma migrations...');
  exec('npx prisma migrate deploy', (error, stdout) => {
    if (error) throw error;
    console.log(stdout);
  });
  
  // Step 2: SQL migrations
  console.log('Running SQL migrations...');
  const pool = new Pool({ connectionString: process.env.DATABASE_URL });
  
  const sqlFiles = fs.readdirSync('./sql-migrations').sort();
  for (const file of sqlFiles) {
    const sql = fs.readFileSync(`./sql-migrations/${file}`, 'utf8');
    await pool.query(sql);
    console.log(`✓ Applied ${file}`);
  }
  
  await pool.end();
  console.log('All migrations complete!');
}

migrate().catch(console.error);
```

**CI/CD Integration** (GitHub Actions):
```yaml
- name: Run Database Migrations
  run: |
    npm run db:migrate
  env:
    DATABASE_URL: ${{ secrets.DATABASE_URL }}
```

### **BE (Backend Engineer)** [Round 8]
**Development workflow**:

**Scenario 1**: Add a new table (common)
```bash
# 1. Edit Prisma schema
vim prisma/schema.prisma

# 2. Generate migration
npx prisma migrate dev --name add_reports_table

# 3. Regenerate Prisma Client
npx prisma generate

# 4. Use in code
const reports = await prisma.report.findMany();
```

**Scenario 2**: Add RLS policy (less common)
```bash
# 1. Create SQL file
vim sql-migrations/005_reports_rls.sql

# 2. Apply manually in dev
psql $DATABASE_URL < sql-migrations/005_reports_rls.sql

# 3. Will auto-apply in production via CI/CD
```

Clear, simple workflow.

### **SA (Software Architect)** [Round 9]
**Migration tracking**:

**Prisma migrations**: Tracked in `_prisma_migrations` table
**SQL migrations**: Need custom tracking

```sql
-- sql-migrations/000_init_tracking.sql
CREATE TABLE IF NOT EXISTS sql_migrations (
  id SERIAL PRIMARY KEY,
  filename VARCHAR(255) UNIQUE NOT NULL,
  applied_at TIMESTAMP DEFAULT NOW()
);
```

**Updated migrate script**:
```javascript
for (const file of sqlFiles) {
  // Check if already applied
  const { rows } = await pool.query(
    'SELECT 1 FROM sql_migrations WHERE filename = $1',
    [file]
  );
  
  if (rows.length === 0) {
    const sql = fs.readFileSync(`./sql-migrations/${file}`, 'utf8');
    await pool.query(sql);
    await pool.query(
      'INSERT INTO sql_migrations (filename) VALUES ($1)',
      [file]
    );
    console.log(`✓ Applied ${file}`);
  } else {
    console.log(`⊘ Skipped ${file} (already applied)`);
  }
}
```

---

## 🎯 Round 10-15: Edge Cases & Rollback

### **TL (Tech Lead)** [Round 10]
**Edge cases**:

**Case 1**: Migration fails mid-execution
- Prisma: Rollback automatic (transactional)
- SQL: Need to wrap in transaction

```sql
BEGIN;
-- Migration statements
COMMIT; -- or ROLLBACK on error
```

**Case 2**: Need to rollback a migration
- Prisma: `prisma migrate resolve --rolled-back <migration>`
- SQL: Create reverse migration file

```sql
-- sql-migrations/006_add_column.sql
ALTER TABLE users ADD COLUMN new_field VARCHAR(255);

-- sql-migrations/006_add_column_rollback.sql
ALTER TABLE users DROP COLUMN new_field;
```

### **DD (Database Developer)** [Round 11]
**Data migration** (not just schema):

**Example**: Migrate existing data to new format
```sql
-- sql-migrations/007_migrate_analytics_format.sql
UPDATE learner_analytics
SET data = jsonb_set(
  data,
  '{velocity}',
  to_jsonb((data->>'topicsPerWeek')::NUMERIC)
)
WHERE data ? 'topicsPerWeek';
```

Prisma can't do complex data transformations. Need SQL.

### **DA (DevOps Architect)** [Round 12]
**Zero-downtime migrations**:

**Problem**: Schema change breaks existing code

**Solution**: Multi-step deployment
1. Deploy backward-compatible schema (add column, don't remove)
2. Deploy new code (uses new column)
3. Deploy cleanup migration (remove old column)

**Example**:
```sql
-- Step 1: Add new column (backward-compatible)
ALTER TABLE users ADD COLUMN email_verified BOOLEAN DEFAULT FALSE;

-- Step 2: (Deploy new code)

-- Step 3: Remove old column
ALTER TABLE users DROP COLUMN is_verified;
```

### **BE (Backend Engineer)** [Round 13]
**Testing migrations**:

**Local testing**:
```bash
# 1. Apply migration to dev database
npm run db:migrate

# 2. Test with seed data
npm run db:seed

# 3. Run tests
npm test

# 4. If issues, rollback
psql $DATABASE_URL < sql-migrations/rollback.sql
```

**CI testing**:
```yaml
test:
  services:
    postgres:
      image: postgres:15
  steps:
    - run: npm run db:migrate
    - run: npm test
```

### **SA (Software Architect)** [Round 14]
**Schema versioning**:

**Prisma**: Automatic (migration history in `_prisma_migrations`)

**SQL**: Manual tracking (our custom `sql_migrations` table)

**Best practice**: Tag database state with Git commit
```sql
INSERT INTO schema_versions (version, git_commit, applied_at)
VALUES ('1.0.0', 'abc123', NOW());
```

Can rollback database to match code version.

### **TL (Tech Lead)** [Round 15]
**Final architecture**:

```
Database Migration Strategy:
├── Prisma Migrate (primary)
│   ├── Tables, columns, indexes
│   ├── Foreign keys, constraints
│   └── Simple PostgreSQL features
│
├── SQL Migrations (advanced)
│   ├── RLS policies (security)
│   ├── Materialized views (performance)
│   ├── Table partitioning (scale)
│   ├── Complex data migrations
│   └── PostgreSQL-specific features
│
└── Deployment Process
    ├── 1. Run Prisma migrations
    ├── 2. Run SQL migrations (with tracking)
    ├── 3. Verify schema health
    └── 4. Rollback on failure
```

---

## ✅ CONSENSUS REACHED

**Decision**: **Hybrid Approach (Prisma Migrate + SQL Migrations)**

**Unanimous Vote**: 5/5 participants approve

**Rationale**:
1. ✅ **Prisma for core schema** - Tables, columns, relationships (90% of changes)
2. ✅ **SQL for advanced features** - RLS, materialized views, partitioning (10% of changes)
3. ✅ **Type safety** - Prisma generates types from schema
4. ✅ **Version control** - All migrations tracked in Git
5. ✅ **Team productivity** - Familiar Prisma CLI for most changes
6. ✅ **PostgreSQL power** - Can use advanced features when needed
7. ✅ **CI/CD friendly** - Automated deployment with custom script

**Implementation Guidelines**:

**1. Prisma Schema** (`prisma/schema.prisma`):
```prisma
generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

// All tables, models, relationships here
```

**2. SQL Migrations** (`sql-migrations/*.sql`):
- Numbered files: `001_rls_policies.sql`, `002_materialized_views.sql`
- Include both forward and rollback versions
- Use transactions for safety

**3. Migration Script** (`database/migrate.js`):
```javascript
async function migrate() {
  // 1. Prisma migrations
  await exec('npx prisma migrate deploy');
  
  // 2. SQL migrations (with tracking)
  await applySQLMigrations();
  
  // 3. Health check
  await verifySchemaHealth();
}
```

**4. Workflow**:
- **Add table**: Edit Prisma schema → `prisma migrate dev`
- **Add RLS**: Create SQL file → Apply in dev → Commit → Auto-deploy
- **Rollback**: Use reverse migration file

**5. CI/CD** (GitHub Actions):
```yaml
deploy:
  steps:
    - name: Database Migrations
      run: npm run db:migrate
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}
```

**Documentation**:
- ADR-003: Database Migration Strategy
- Guide: `docs/guides/database-migrations.md`
- Examples: `database/examples/`

**Timeline**: 2 days (setup + documentation)

**Next Steps**:
- Proceed to Debate #4: External Microservice Mock Data Strategy
- Document migration strategy in Phase 1A deliverables

---

**Debate Completed**: October 24, 2025  
**Status**: ✅ CONSENSUS ACHIEVED  
**Decision**: Hybrid (Prisma Migrate + SQL Migrations)

