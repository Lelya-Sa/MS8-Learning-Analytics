# Learning Analytics Microservice â€” User Journey Flow

**Service**: Learning Analytics Microservice (#8)

**Version**: 1.0

**Date**: October 24, 2025

**Status**: Authoritative UX flow reference

---

## ğŸ¯ Purpose

Define clear, endâ€‘toâ€‘end user journeys across roles for the Learning Analytics microservice, aligning UX steps with backend data flows, APIs, caching, and testing. This serves product, design, engineering, and QA for a shared, testable understanding of the experience.

---

## ğŸ‘¥ Roles Covered

- Learner
- Trainer
- Organization Manager (HR)
- Platform Admin
- Multiâ€‘Role (seamless role switching)

---

## ğŸ§­ Principles

- Fast timeâ€‘toâ€‘firstâ€‘insight with progressive rendering (SWR strategy)
- Clear loading states and actionable empty states
- Privacyâ€‘first UX (explicit consent, data scopes, GDPR flows)
- Deterministic navigation, consistent across roles
- Resilient to partial data and background refreshes

---

## ğŸ—ºï¸ Global Flow Overview

```
USER â†’ Auth (JWT) â†’ Dashboard Shell (SWR) â†’ Data Availability Check
   â””â”€ if first-time or stale data â†’ Batch Pipeline trigger/await
      â””â”€ Stage 1: Collect from 9 microservices
      â””â”€ Stage 2: Analysis Engine (parallel compute)
      â””â”€ Stage 3: Aggregate & refresh materialized views
UI progressively hydrates sections as views become available
```

Key UX states: "Analyzing your learning dataâ€¦", skeleton charts, sectionâ€‘level spinners, lastâ€‘updated timestamps, and retry/notify options for long batches.

---

## ğŸ“š Related Authoritative Docs

- Architecture overview: `01-Architecture/Architecture-Overview.md`
- Decisions: `01-Architecture/Implementation-Decisions-Log.md`
- Processing pipeline: `03-Data-Schemas/02-PROCESSING/Processing-Pipeline-Complete.md`
- Data lineage visualization: `03-Data-Schemas/02-PROCESSING/Data-Lineage-Flow.md`
- Topic learning path flow: `03-Data-Schemas/03-DATA-MODELS/Complete-Topic-Based-Learning-Path-Flow.md`
- Multiâ€‘role support: `03-Data-Schemas/03-DATA-MODELS/Multi-Role-Support-Architecture.md`
- E2E journeys (tests): `05-Testing-TDD/03-System-Tests-Design/E2E-Tests-Complete.md`

---

## ğŸ§ª Data Readiness & SWR Contract

- Dashboard requests read from materialized views; if missing/stale, UI shows loading and initiates/awaits refresh.
- Section hydration is independent: each analytic panel renders when its view is ready.
- SLA targets: timeâ€‘toâ€‘firstâ€‘content â‰¤ 2s; firstâ€‘time full hydration â‰¤ ~45s; returning users â‰¤ 2s for cached views.

---

## ğŸ“ Learner Journeys

### L1 â€” Firstâ€‘Time Onboarding to First Insights

1. Sign in â†’ receive JWT (role: Learner)
2. Consent screen (privacy/GDPR) â†’ confirm scopes
3. Landing on Dashboard Shell (SWR): skeleton layout + "Analyzing your learning dataâ€¦"
4. Pipeline runs (Stages 1â€‘3); panels hydrate as views refresh
5. Explore key analytics: learning velocity, skill gaps, engagement
6. Generate first report (PDF/CSV) and share/export
7. Optional: Ask AI for "3 actions to improve this week"

Success criteria:
- Insights visible within 45s on first run; clear progress indicators
- No empty white screens; every panel has a meaningful placeholder
- Report generated with consistent totals vs onâ€‘screen metrics

### L2 â€” Returning Daily Checkâ€‘In

1. Sign in â†’ role reminder (Learner) â†’ Dashboard loads from cache
2. Panels show lastâ€‘updated; background refresh begins
3. Notifications: new completions, streaks, atâ€‘risk signals
4. AI tip of the day based on recent activity

Success criteria:
- Timeâ€‘toâ€‘interactive â‰¤ 2s; visual refresh indicators per section
- No blocking spinners; user can navigate while data updates

### L3 â€” Learning Path Review & Adjustment (Topicâ€‘Based)

1. Open Learning Path â†’ view acquired vs pending topics
2. Inspect skillâ†’topic mapping and blockers
3. Accept AI recommendation to reorder next 3 topics
4. Save plan â†’ immediate reflection in "Next Up" widget

Success criteria:
- Topic counts match analytics; recommendations are contextual and reversible

---

## ğŸ‘©â€ğŸ« Trainer Journeys

### T1 â€” Course Health Monitoring

1. Switch to Trainer role â†’ course selector
2. View cohort funnel, completion rate, assessment distribution
3. Drill into outliers; tag followâ€‘up actions
4. Export course snapshot report

Success criteria:
- Cohort metrics consistent with raw counts; exports match onâ€‘screen aggregates

### T2 â€” Atâ€‘Risk Learner Identification

1. Open "Atâ€‘Risk" panel â†’ sorted by risk score
2. Filter by segment (e.g., week 3 beginners)
3. Generate intervention list; optionally notify LMS

Success criteria:
- Deterministic ordering; filters persist; audit trail recorded

---

## ğŸ¢ Organization Manager (HR) Journeys

### O1 â€” Team Analytics Overview

1. Switch to Org Manager role â†’ team dashboard
2. View engagement heatmap, skills coverage, progress deltas
3. Compare cohorts; download executive summary

Success criteria:
- Anonymized peer comparisons; no PII leaks; reproducible summary totals

### O2 â€” Compliance & Evidence

1. Open compliance view â†’ mandatory course completion status
2. Export evidence pack (timeâ€‘stamped)

Success criteria:
- Exports are signed/dated; totals agree with course systems

---

## ğŸ› ï¸ Platform Admin Journeys

### A1 â€” System Health & Data Freshness

1. Open Admin panel â†’ storage usage, materialized views freshness
2. Manually trigger refresh for lagging views (if needed)
3. Review error budgets and slow queries

Success criteria:
- All views within freshness SLOs; refreshes are idempotent and observable

### A2 â€” RBAC & Role Validation

1. Inspect a multiâ€‘role userâ€™s access â†’ verify scope boundaries
2. Run audit log query; export access report

Success criteria:
- No crossâ€‘role data leakage; audit logs complete and consistent

---

## ğŸ” Multiâ€‘Role Journey (Seamless Switching)

1. User opens role switcher (Learner â†” Trainer â†” Org Manager â†” Admin)
2. Context switch without reâ€‘auth; dashboard rebinds to roleâ€‘scoped data
3. Prior filters preserved where applicable; crossâ€‘role comparison is anonymized

Success criteria:
- Switch roundâ€‘trip â‰¤ 1s; no residue of prior role data visible

---

## âš ï¸ Error & Edge States

- Partial Data: Panels show scoped placeholders and last successful snapshot
- Longâ€‘Running Batches: Offer "Email me when ready" and nonâ€‘blocking navigation
- Upstream Outage (one microservice): Panel degraded with provenance note
- Permission Denied: Explain role scope and offer role switch
- GDPR Requests in Progress: Temporarily suppress personal insights with status notice

---

## ğŸ“ Quality Gates & Metrics

- Performance: TTFI â‰¤ 2s; firstâ€‘time full hydration â‰¤ ~45s
- Freshness: Materialized views within SLOs per category
- Consistency: Export totals match visible aggregates
- Privacy: Zero PII in peer comparisons; consent captured and auditable
- Observability: Every user action emits trace + audit logs with correlation IDs

---

## ğŸ”— Mapping to Tests & APIs

- E2E coverage: see `05-Testing-TDD/03-System-Tests-Design/E2E-Tests-Complete.md` (Learner, Trainer, Org, Admin, Multiâ€‘Role paths)
- Feature tests: see `05-Testing-TDD/01-Test-Designs/` (Data collection, Batch processing, AI insights)
- APIs: `02-API-Documentation/API-Overview.md` and role UX APIs in `02-API-Documentation/User-Experience-APIs.md`

---

## âœ… Definition of Done (User Journey)

- Journeys render correctly across roles with SWR hydration
- Edge states covered with actionable UX
- Tests passing for critical paths; exports consistent
- Observability and audit complete; RBAC enforced


